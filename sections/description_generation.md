| Title                                                                                                   | Author(s)                                                                                             |   Year | Venue       | Code                                                                    |
|:--------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------|-------:|:------------|:------------------------------------------------------------------------|
| Show and Tell: A Neural Image Caption Generator                                                         | Oriol Vinyals et al.                                                                                  |   2015 | CVPR        | -                                                                       |
| Show, Attend and Tell: Neural Image Caption Generation with Visual Attention                            | Kelvin Xu et al.                                                                                      |   2015 | ICML        | https://github.com/kelvinxu/arctic-captions                             |
| Multilingual Image Description with Neural Sequence Models                                              | Desmond Elliott et al.                                                                                |   2015 | -           | -                                                                       |
| Cross-modal Coherence Modeling for Caption Generation                                                   | Malihe Alikhani et al.                                                                                |   2020 | ACL         | https://github.com/malihealikhani/Cross-modal_Coherence_Modeling        |
| VideoBERT: A Joint Model for Video and Language Representation Learning                                 | Chen Sun et al.                                                                                       |   2019 | CVPR        | -                                                                       |
| Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints               | Jieyu Zhao et al.                                                                                     |   2017 | EMNLP       | https://github.com/uclanlp/reducingbias                                 |
| Women Also Snowboard:Overcoming Bias in Captioning Models                                               | Lisa Anne Hendricks et al.                                                                            |   2018 | ECCV        | -                                                                       |
| Multimodal Explanations: Justifying Decisions and Pointing to the Evidence                              | Dong Huk Park et al.                                                                                  |   2018 | CVPR        | -                                                                       |
| Multimodal Neural Language Models                                                                       | Ryan Kiros et al.                                                                                     |   2014 | ICML        | -                                                                       |
| Learning Multimodal Attention LSTM Networks for Video Captioning                                        | Jun Xu, Ting Yao, Yongdong Zhang, Yongdong Zhang, Tao Mei                                             |   2017 | ACM MM      | -                                                                       |
| A Case Study on Combining ASR and Visual Features for Generating Instructional Video Captions           | Jack Hessel, Bo Pang, Zhenhai Zhu, Radu Soricut                                                       |   2019 | CoNLL       | -                                                                       |
| Fast, Diverse and Accurate Image Captioning Guided By Part-of-Speech                                    | Aditya Deshpande et al.                                                                               |   2019 | CVPR        | -                                                                       |
| Show, Control and Tell: A Framework for Generating Controllable and Grounded Captions.                  | Marcella Cornia et al.                                                                                |   2019 | CVPR        | https://github.com/aimagelab/show-control-and-tell                      |
| Unpaired Image Captioning by Language Pivoting                                                          | Jiuxiang Gu et al.                                                                                    |   2018 | ECCV        | -                                                                       |
| ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks        | Jiasen Lu, Dhruv Batra, Devi Parikh, Stefan Lee                                                       |   2019 | NeurIPS     | https://github.com/facebookresearch/vilbert-multi-task                  |
| Video Captioning with Multi-Faceted Attention                                                           | Xiang Long et al.                                                                                     |   2018 | TACL        | -                                                                       |
| Generating Image Descriptions using Multilingual Data                                                   | Alan Jaffe                                                                                            |   2017 | WMT         | -                                                                       |
| Attend to you: Personalized image captioning with context sequence memory networks                      | Cesc Chunseong Par et al.                                                                             |   2017 | CVPR        | https://github.com/cesc-park/attend2u                                   |
| Two Birds, One Stone: A Simple, Unified Model for Text Generation from Structured and Unstructured Data | Hamidreza Shahidi et al.                                                                              |   2020 | ACL         | https://github.com/h-shahidi/2birds-gen                                 |
| Unsupervised Stylish Image Description Generation via Domain Layer Norm                                 | Cheng-Kuan Chen et al.                                                                                |   2019 | AAAI        | -                                                                       |
| Engaging Image Captioning via Personality                                                               | Kurt Shuster et al.                                                                                   |   2019 | CVPR        | -                                                                       |
| Video to Text Summary: Joint Video Summarization and Captioning with Recurrent Neural Networks          | Bor-Chun Chen et al.                                                                                  |   2017 | BMVC        | -                                                                       |
| Cross-Lingual Image Caption Generation                                                                  | Takashi Miyazaki, Nobuyuki Shimizu                                                                    |   2016 | ACL         | -                                                                       |
| Fluency-Guided Cross-Lingual Image Captioning                                                           | Weiyu Lan et al.                                                                                      |   2017 | ACM MM      | https://github.com/weiyuk/fluent-cap                                    |
| A Multi-task Learning Approach for Image Captioning                                                     | Wei Zhao et al.                                                                                       |   2018 | IJCAI       | https://github.com/andyweizhao/Multitask_Image_Captioning               |
| End-to-End Video Captioning with Multitask Reinforcement Learning                                       | Lijun Li, Boqing Gong                                                                                 |   2019 | WACV        | https://github.com/adwardlee/multitask-end-to-end-video-captioning      |
| One model to learn them all                                                                             | Lukasz Kaiser et al.                                                                                  |   2017 | arxiv       | https://github.com/tensorflow/tensor2tensor                             |
| Cross-Lingual Image Caption Generation Based on Visual Attention Model                                  | Bin Wang et al.                                                                                       |   2020 | IEEE Access | -                                                                       |
| Mutli-task Sequence-to-sequence Learning                                                                | Minh-Thang Luong et al.                                                                               |   2016 | ICLR        | -                                                                       |
| Towards Faithful Neural Table-to-Text Generation with Content-Matching Constraints                      | Zhenyi Wang et al.                                                                                    |   2020 | ACL         | -                                                                       |
| Logical Natural Language Generation from Open-Domain Tables                                             | Wenhu Chen et al.                                                                                     |   2020 | ACL         | https://github.com/wenhuchen/LogicNLG                                   |
| VATEX: A Large-Scale, High-Quality Multilingual Dataset for Video-and-Language Research                 | Xin Wang et al.                                                                                       |   2019 | ICCV        | https://github.com/eric-xw/Video-guided-Machine-Translation             |
| Grounding action descriptions in videos.                                                                | Michaela Regneri et al.                                                                               |   2013 | TACL        | -                                                                       |
| Sequence to Sequence - Video to Text                                                                    | Subhashini Venugopalan, Marcus Rohrbach, Jeffrey Donahue, Raymond Mooney, Trevor Darrell, Kate Saenko |   2015 | ICCV        | https://github.com/vsubhashini/caffe/tree/recurrent/examples/s2vt       |
| CapWAP: Image Captioning with a Purpose                                                                 | Adam Fisch, Kenton Lee, Ming-Wei Chang, Jonathan Clark, Regina Barzilay                               |   2020 | EMNLP       | https://github.com/google-research/language/tree/master/language/capwap |
| Multilingual AMR-to-Text Generation                                                                     | Angela Fan, Claire Gardent                                                                            |   2020 | EMNLP       | https://github.com/facebookresearch/m-amr2text                          |